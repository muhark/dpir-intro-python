{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Coding Tutorial 5: Unsupervised Learning\n",
    "\n",
    "In this coding tutorial, we learn how to do the following for `k-means` clustering and principal components analysis:\n",
    "\n",
    "- Import models from `scikit-learn`\n",
    "- Prepare a pandas dataframe for analysis with `scikit-learn`\n",
    "- Instantiate and fit a model to data\n",
    "- Visualise the results of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Importing Models from Scikit-Learn\n",
    "\n",
    "`scikit-learn` is actually a collection of modules, so you will need to find which sub-module contains the model you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# scikit-learn imports\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# import the data\n",
    "link = 'http://github.com/muhark/dpir-intro-python/raw/master/Week2/data/bes_data_subset_week2.feather'\n",
    "df = pd.read_feather(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Data Pre-Processing\n",
    "\n",
    "There are four steps for preparing data for analysis:\n",
    "\n",
    "1. Feature Selection\n",
    "2. Accounting for NAs\n",
    "3. One Hot Encoding\n",
    "4. Conversion to numpy ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Feature Selection\n",
    "\n",
    "Here we just choose which columns we are going to use. If your data has a lot of NAs, it may be worthwhile to prefer columns with fewer NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "features = ['region', 'Age', 'a02', 'a03', 'e01',\n",
    "            'k01', 'k02', 'k11', 'k13', 'k06', 'k08',\n",
    "            'y01', 'y03', 'y06', 'y08', 'y09', 'y11', 'y17']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Accounting for NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Can check for na's with:\n",
    "# df[features].isna().sum()\n",
    "df = df[features].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## One-Hot Encoding\n",
    "\n",
    "We can do a one-hot encoding using the `pd.get_dummies()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.get_dummies(df)\n",
    "print(df.shape, data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Normalization and Conversion to `numpy`\n",
    "\n",
    "We call the `StandardScaler().fit_transform()` function on the `.values` argument of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X = data.values\n",
    "scaler = StandardScaler()\n",
    "X_norm = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Instantiating and Fitting `k-means`\n",
    "\n",
    "We first create an instance of the model, where we provide parameters, and then we pass data to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, random_state=634)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "kmeans.fit(X_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can extract the labels using the `.labels_` method, and then assign them to a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df['labels_'] = kmeans.labels_\n",
    "df['labels_'] = df['labels_'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Visualising the Results\n",
    "\n",
    "This is a bit difficult with so many variables. Let's look at age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(15, 8))\n",
    "sns.histplot(df[['labels_', 'Age']].sort_values('labels_'),\n",
    "             x='Age', ax=ax, kde=True, hue='labels_');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# We can appropriate this function\n",
    "def grouped_barplot(data, var1, var2):\n",
    "    \"\"\"\n",
    "    Creates a grouped bar plot of the distribution of `var2` within each group of `var2`.\n",
    "    \"\"\"\n",
    "    temp = data.groupby([var1, var2]).apply(len).reset_index().rename({0: 'Count'}, axis=1)\n",
    "    f, ax = plt.subplots(1, 1, figsize=(len(data[var1].unique())*len(data[var1].unique())/5, 10))\n",
    "    sns.barplot(data=temp, x=var1, y='Count', hue=var2)\n",
    "    ax.set_title(f\"BES Sample {var2} per {var1}\")\n",
    "    ax.xaxis.set_ticklabels(ax.xaxis.get_ticklabels(), rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "grouped_barplot(df, 'a02','labels_') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "grouped_barplot(df, 'region','labels_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Instantiating and Fitting PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2, random_state=634)\n",
    "pca = pca.fit(X_norm)\n",
    "reduced_X = pca.fit_transform(X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=reduced_X[:, 0], y=reduced_X[:, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Combining PCA and `k-means`\n",
    "\n",
    "We can fit k-means to PCA-reduced data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pcakmeans = KMeans(n_clusters=5, random_state=634)\n",
    "pcakmeans.fit(reduced_X)\n",
    "df['pcakmeans_labels'] = pcakmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "f, ax = plt.subplots(1, 1, figsize=(15, 8))\n",
    "sns.scatterplot(x=reduced_X[:, 0], y=reduced_X[:, 1],\n",
    "                hue=pcakmeans.labels_,\n",
    "                palette=sns.color_palette(palette='colorblind', n_colors=5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "grouped_barplot(df, 'a02', 'pcakmeans_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pca.components_, columns=data.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
